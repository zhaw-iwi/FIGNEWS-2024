{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT for Linguistic Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for this project\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import os\n",
    "from utils import append_data, lm_completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sys-admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Sheets API\n",
    "gc = gspread.service_account(filename='fignews-7b178eec49aa.json')\n",
    "SHEET_ID = \"1e_KpDnyNriLSNWMt-qIvcqGqtH_JC9YrzoMDHNiqdNA\"\n",
    "SHEET_NAME = \"NwayMain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Sample Data from Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch Source Language  ID  Type  \\\n",
      "0   B01         English   1  MAIN   \n",
      "1   B01         English   2  MAIN   \n",
      "2   B01         English   4  MAIN   \n",
      "3   B01         English   7  MAIN   \n",
      "4   B01         English   8  MAIN   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Yemen's Houthis have waded into the Israel-Ham...   \n",
      "1             Isreal - Hamas Conflict | Face to Face   \n",
      "2  Videos show how armed men from Gaza stormed a ...   \n",
      "3  Protest in Aligarh Muslim University in suppor...   \n",
      "4  IDF releases audio recording about misfired ro...   \n",
      "\n",
      "                                          English MT  \\\n",
      "0  Yemen's Houthis have waded into the Israel-Ham...   \n",
      "1             Isreal - Hamas Conflict | Face to Face   \n",
      "2  Videos show how armed men from Gaza stormed a ...   \n",
      "3  Protest in Aligarh Muslim University in suppor...   \n",
      "4  IDF releases audio recording about misfired ro...   \n",
      "\n",
      "                                           Arabic MT  Annotator ID_1  \\\n",
      "0  خاض الحوثيون في اليمن الحرب بين إسرائيل وحماس ...               1   \n",
      "1               إسرائيل - الصراع مع حماس | وجها لوجه               1   \n",
      "2  أظهرت مقاطع فيديو كيف اقتحم مسلحون من غزة مهرج...               1   \n",
      "3  وقفة احتجاجية في جامعة عليكرة الإسلامية دعما ل...               1   \n",
      "4  الجيش الإسرائيلي ينشر تسجيلًا صوتيًا حول صاروخ...               1   \n",
      "\n",
      "     Bias_1    Propaganda_1  ...  Propaganda_3 Annotator ID_4 Bias_4  \\\n",
      "0  Unbiased  Not Propaganda  ...                            4          \n",
      "1  Unbiased  Not Propaganda  ...                            4          \n",
      "2  Unbiased      Propaganda  ...                            4          \n",
      "3   Unclear         Unclear  ...                            4          \n",
      "4  Unbiased  Not Propaganda  ...                            4          \n",
      "\n",
      "   Propaganda_4 N-way count bias N-way count propaganda  Agreement Bias  \\\n",
      "0                              1                      1               1   \n",
      "1                              1                      1                   \n",
      "2                              1                      1                   \n",
      "3                              1                      1                   \n",
      "4                              1                      1                   \n",
      "\n",
      "  Agreement Propaganda                      GPT3.5 connotation annotation  \\\n",
      "0                    1  Yemen's Houthis have waded into the Israel-Ham...   \n",
      "1                       Isreal - Hamas Conflict | Face to Face\\n\\nThe ...   \n",
      "2                       Videos show how armed men from Gaza stormed a ...   \n",
      "3                       Protest in Aligarh Muslim University in suppor...   \n",
      "4                       IDF releases audio recording[factuality] about...   \n",
      "\n",
      "   GPT 4 connotation annotation  \n",
      "0         Biased against others  \n",
      "1                       Unclear  \n",
      "2      Biased against Palestine  \n",
      "3         Biased against Israel  \n",
      "4                      Unbiased  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Annotator ID_1</th>\n",
       "      <th>Annotator ID_2</th>\n",
       "      <th>Annotator ID_3</th>\n",
       "      <th>Annotator ID_4</th>\n",
       "      <th>N-way count bias</th>\n",
       "      <th>N-way count propaganda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2641.267222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.413889</td>\n",
       "      <td>0.413333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4519.388845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492666</td>\n",
       "      <td>0.492568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>286.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>957.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3500.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42210.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID  Annotator ID_1  Annotator ID_2  Annotator ID_3  \\\n",
       "count   1800.000000          1800.0          1800.0          1800.0   \n",
       "mean    2641.267222             1.0             2.0             3.0   \n",
       "std     4519.388845             0.0             0.0             0.0   \n",
       "min        1.000000             1.0             2.0             3.0   \n",
       "25%      286.750000             1.0             2.0             3.0   \n",
       "50%      957.000000             1.0             2.0             3.0   \n",
       "75%     3500.750000             1.0             2.0             3.0   \n",
       "max    42210.000000             1.0             2.0             3.0   \n",
       "\n",
       "       Annotator ID_4  N-way count bias  N-way count propaganda  \n",
       "count          1800.0       1800.000000             1800.000000  \n",
       "mean              4.0          0.413889                0.413333  \n",
       "std               0.0          0.492666                0.492568  \n",
       "min               4.0          0.000000                0.000000  \n",
       "25%               4.0          0.000000                0.000000  \n",
       "50%               4.0          0.000000                0.000000  \n",
       "75%               4.0          1.000000                1.000000  \n",
       "max               4.0          1.000000                1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spreadsheet = gc.open_by_key(SHEET_ID)\n",
    "worksheet = spreadsheet.worksheet(SHEET_NAME)\n",
    "rows = worksheet.get_all_records()\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.head(5))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tag(df):\n",
    "    \n",
    "    prompt: str = \"\"\"\n",
    "    You are an expert in linguistic media bias detection. Evaluate the text based solely on the language used to describe actions or parties and assign the appropriate label according to the following criteria:\n",
    "    Unbiased: Label as \"Unbiased\" if the text reports events in a straightforward and factual manner without using language that emotionally charges or slants the description towards either approval or disapproval. The language should not imply moral judgments.\n",
    "    Biased against Palestine: Label as \"Biased against Palestine\" only if the text uses language that specifically denigrates Palestine or Palestinians, such as using pejorative terms, unfounded accusations, or portraying actions without equivalent descriptions of similar actions by others. This bias should be clear and direct, not inferred from neutral descriptions of conflict actions. Talking about Hamas does not automatically imply Bias against Palestine.\n",
    "    Biased against Israel: Use this label if the language portrays Israel or Israelis negatively through the use of loaded language or misrepresentation. This could include terms that unfairly categorize Israeli actions or policies, such as using \"genocide\" without factual backing or negative descriptors for Israeli military actions not used for similar actions by others.\n",
    "    Biased against both Palestine and Israel: Use this label if the text uses language that negatively portrays both sides, suggesting hostility or illegitimacy towards both, often using a tone that ridicules or condemns the conflict or both parties involved.\n",
    "    Biased against others: Apply this label if the bias is directed towards other entities not directly related to the Israel-Palestine conflict. If multiple entities including Israel and/or Palestine are portrayed negatively, choose the most specific label relevant to the content.\n",
    "    Unclear: Choose \"Unclear\" if the text lacks sufficient context to determine the presence of bias or if the language is ambiguous without clear indications of leaning towards or against any party.\n",
    "    Not Applicable: Select \"Not Applicable\" for texts that are irrelevant to the task or unrelated to any conflict involving Israel and Palestine.\n",
    "\n",
    "    Clarify that descriptions of conflict or military actions in themselves do not constitute bias unless coupled with language that unjustly portrays one side in a morally negative light compared to the other.\n",
    "    Encourage checking if comparable actions by different sides are described differently; this disparity can indicate bias. Check the label defintions above for more guidance.\n",
    "    Respond with the label only, without any prefix or additional explanation.\n",
    "    Example for Analysis:\n",
    "    \"\"\"\n",
    "    df['GPT-4 Bias proposal'] = df['English MT'].apply(lambda row: lm_completion([\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"system\", \"content\": row}]))\n",
    "    return df\n",
    "\n",
    "df_annotated = apply_tag(df)\n",
    "print(df_annotated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated.to_excel(\"bias_annotation_gpt4.xlsx\")\n",
    "append_data(df_annotated[[\"GPT-4 Bias proposal\"]], worksheet, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_connotations(df):\n",
    "    prompt: str = \"\"\"\n",
    "    You are an expert in detecting linguistic media bias through word connotations and implications about factuality in texts. Your task is to label specific types of words in a text according to the following criteria:\n",
    "\n",
    "    [negative]: Use this label for words that clearly carry a negative connotation, influencing the reader's perception negatively.\n",
    "    [positive]: Use this label for words that clearly have a positive connotation, influencing the reader's perception positively.\n",
    "    [factuality]: Use this label for words that cast doubt or imply uncertainty about the factuality of the information presented.\n",
    "    Focus on tagging verbs, adjectives, and adverbs. Avoid tagging named entities or neutral words. Label directly after the word it applies to. For example:\n",
    "\n",
    "    This is an awful[negative] text.\n",
    "    Do not change anything else about the text. Just add the tags where applicable. Here is the text for analysis:\n",
    "    \"\"\"\n",
    "    df['GPT-4 connotation'] = df['English MT'].apply(lambda row: lm_completion([\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"system\", \"content\": row}]))\n",
    "    return df\n",
    "\n",
    "df_annotated_connotations = tag_connotations(df)\n",
    "print(df_annotated_connotations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_connotations.to_excel(\"annotated_connotations_full_run.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Google Sheets with our Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch Source Language  ID  Type  \\\n",
      "0   B01         English   1  MAIN   \n",
      "1   B01         English   2  MAIN   \n",
      "2   B01         English   4  MAIN   \n",
      "3   B01         English   7  MAIN   \n",
      "4   B01         English   8  MAIN   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Yemen's Houthis have waded into the Israel-Ham...   \n",
      "1             Isreal - Hamas Conflict | Face to Face   \n",
      "2  Videos show how armed men from Gaza stormed a ...   \n",
      "3  Protest in Aligarh Muslim University in suppor...   \n",
      "4  IDF releases audio recording about misfired ro...   \n",
      "\n",
      "                                          English MT  \\\n",
      "0  Yemen's Houthis have waded into the Israel-Ham...   \n",
      "1             Isreal - Hamas Conflict | Face to Face   \n",
      "2  Videos show how armed men from Gaza stormed a ...   \n",
      "3  Protest in Aligarh Muslim University in suppor...   \n",
      "4  IDF releases audio recording about misfired ro...   \n",
      "\n",
      "                                           Arabic MT  Annotator ID_1  \\\n",
      "0  خاض الحوثيون في اليمن الحرب بين إسرائيل وحماس ...               1   \n",
      "1               إسرائيل - الصراع مع حماس | وجها لوجه               1   \n",
      "2  أظهرت مقاطع فيديو كيف اقتحم مسلحون من غزة مهرج...               1   \n",
      "3  وقفة احتجاجية في جامعة عليكرة الإسلامية دعما ل...               1   \n",
      "4  الجيش الإسرائيلي ينشر تسجيلًا صوتيًا حول صاروخ...               1   \n",
      "\n",
      "     Bias_1    Propaganda_1  ...  Annotator ID_4 Bias_4 Propaganda_4  \\\n",
      "0  Unbiased  Not Propaganda  ...               4                       \n",
      "1  Unbiased  Not Propaganda  ...               4                       \n",
      "2  Unbiased      Propaganda  ...               4                       \n",
      "3   Unclear         Unclear  ...               4                       \n",
      "4  Unbiased  Not Propaganda  ...               4                       \n",
      "\n",
      "   N-way count bias N-way count propaganda Agreement Bias  \\\n",
      "0                 1                      1              1   \n",
      "1                 1                      1                  \n",
      "2                 1                      1                  \n",
      "3                 1                      1                  \n",
      "4                 1                      1                  \n",
      "\n",
      "   Agreement Propaganda                      GPT3.5 connotation annotation  \\\n",
      "0                     1  Yemen's Houthis have waded into the Israel-Ham...   \n",
      "1                        Isreal - Hamas Conflict | Face to Face\\n\\nThe ...   \n",
      "2                        Videos show how armed men from Gaza stormed a ...   \n",
      "3                        Protest in Aligarh Muslim University in suppor...   \n",
      "4                        IDF releases audio recording[factuality] about...   \n",
      "\n",
      "  GPT 4 connotation annotation  GPT-4 Bias proposal  \n",
      "0        Biased against others       Not Propaganda  \n",
      "1                      Unclear              Unclear  \n",
      "2     Biased against Palestine       Not Propaganda  \n",
      "3        Biased against Israel           Propaganda  \n",
      "4                     Unbiased       Not Propaganda  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "def apply_propaganda_tag(df):\n",
    "    \n",
    "    prompt: str = \"\"\"\n",
    "    You are an expert in linguistic media propaganda detection. Carefully evaluate the text based on the language used and the context provided, and assign the appropriate label according to the refined criteria below. Respond with the label only, without any prefix or additional explanation.\n",
    "    Definitions and Criteria:\n",
    "    Propaganda: Use this label for texts that actively promote a specific political or ideological agenda through highly charged emotional language, overt promotional statements, or a selective presentation of facts that clearly aim to manipulate public perception. Examples include texts that celebrate military actions with terms like \"win\" against \"terror,\" implying a righteous cause, or that frame conflict participants in a manner that clearly supports one side over another.\n",
    "    Not Propaganda: Apply this label to texts that, while potentially using biased language, do not combine this with overt calls to action or explicit valorization/demonization that manipulates public perception. A statement reporting expected military actions or describing events without additional commentary or emotional framing should be considered under this category, even if it includes terms like \"terror attacks\" which may reflect some level of bias but do not by themselves constitute propaganda.\n",
    "    Unclear: This label should be used for texts where the intent to inform or persuade is not clear-cut, particularly in brief texts or statements where contextual cues are minimal.\n",
    "    Not Applicable: Use this label for texts that do not engage in any form of persuasive communication about controversial or conflict-related issues.\n",
    "    Additional Guidance for Annotators:\n",
    "    Evaluating the Intensity of Language: Focus on how intensely the language used in the text promotes one side or demeans another. Propaganda typically involves a strong bias towards one perspective, often accompanied by language that seeks to evoke a specific emotional response from the audience.\n",
    "    Contextual Sensitivity: Consider the broader media context and the usual reporting style of the source. This can provide clues about whether a statement is part of a pattern of propaganda or a more isolated instance of biased reporting.\n",
    "    Example for Analysis:\n",
    "    \"\"\"\n",
    "    df['GPT-4 Propaganda proposal'] = df['English MT'].apply(lambda row: lm_completion([\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"system\", \"content\": row}]))\n",
    "    return df\n",
    "\n",
    "df_annotated = apply_propaganda_tag(df)\n",
    "print(df_annotated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated.to_excel(\"annotated_propanda.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_data(df_annotated[[\"GPT-4 Propanda proposal\"]], worksheet, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
