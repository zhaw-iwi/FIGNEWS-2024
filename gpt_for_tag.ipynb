{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT for Linguistic Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for this project\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import os\n",
    "from utils import append_data, lm_completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sys-admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Sheets API\n",
    "gc = gspread.service_account(filename='fignews-7b178eec49aa.json')\n",
    "SHEET_ID = \"1e_KpDnyNriLSNWMt-qIvcqGqtH_JC9YrzoMDHNiqdNA\"\n",
    "SHEET_NAME = \"NwayMain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Sample Data from Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 ID  Annotator ID_1  Annotator ID_2  Annotator ID_3  \\\n",
      "count   1800.000000          1800.0          1800.0          1800.0   \n",
      "mean    2641.267222             1.0             2.0             3.0   \n",
      "std     4519.388845             0.0             0.0             0.0   \n",
      "min        1.000000             1.0             2.0             3.0   \n",
      "25%      286.750000             1.0             2.0             3.0   \n",
      "50%      957.000000             1.0             2.0             3.0   \n",
      "75%     3500.750000             1.0             2.0             3.0   \n",
      "max    42210.000000             1.0             2.0             3.0   \n",
      "\n",
      "       Annotator ID_4  N-way count bias  N-way count propaganda  \n",
      "count          1800.0       1800.000000             1800.000000  \n",
      "mean              4.0          0.255556                0.255000  \n",
      "std               0.0          0.436294                0.435982  \n",
      "min               4.0          0.000000                0.000000  \n",
      "25%               4.0          0.000000                0.000000  \n",
      "50%               4.0          0.000000                0.000000  \n",
      "75%               4.0          1.000000                1.000000  \n",
      "max               4.0          1.000000                1.000000  \n"
     ]
    }
   ],
   "source": [
    "spreadsheet = gc.open_by_key(SHEET_ID)\n",
    "worksheet = spreadsheet.worksheet(SHEET_NAME)\n",
    "rows = worksheet.get_all_records()\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Batch Source Language     ID  Type  \\\n",
      "2149    B03          Arabic  14521  MAIN   \n",
      "1833    B03         English    673  MAIN   \n",
      "309     B01          Arabic   3530  MAIN   \n",
      "11796   B14         English   3727  MAIN   \n",
      "12011   B14          Arabic   9325  MAIN   \n",
      "\n",
      "                                                    Text  \\\n",
      "2149   \"فتح\": تصريحات المدعو حماد تعبر عن انحطاط وطني...   \n",
      "1833   HAPPENING NOW: Pres. Biden delivers remarks af...   \n",
      "309    بدأ عملها بخطف جلعاد شاليط، وكانت المسؤولة عن ...   \n",
      "11796  The Republican presidential candidates all cal...   \n",
      "12011  منذ 15 عاماً.. 4 حروب اندلعت بين الفلسطينيين و...   \n",
      "\n",
      "                                              English MT  \\\n",
      "2149   \"Fatah\": The statements of the so-called Hamma...   \n",
      "1833   HAPPENING NOW: Pres. Biden delivers remarks af...   \n",
      "309    Her work began with the kidnapping of Gilad Sh...   \n",
      "11796  The Republican presidential candidates all cal...   \n",
      "12011  15 years ago... 4 wars broke out between Pales...   \n",
      "\n",
      "                                               Arabic MT Annotator ID Bias  \\\n",
      "2149   \"فتح\": تصريحات المدعو حماد تعبر عن انحطاط وطني...                     \n",
      "1833   يحدث الآن: الرئيس. بايدن يدلي بتصريحاته بعد إط...                     \n",
      "309    بدأ عملها بخطف جلعاد شاليط، وكانت المسؤولة عن ...                     \n",
      "11796  وقد دعا جميع المرشحين الرئاسيين الجمهوريين الو...                     \n",
      "12011  منذ 15 عاماً.. 4 حروب اندلعت بين الفلسطينيين و...                     \n",
      "\n",
      "      Propaganda Comments                GPT proposal  \n",
      "2149                         Biased against Palestine  \n",
      "1833                                         Unbiased  \n",
      "309                                          Unbiased  \n",
      "11796                                        Unbiased  \n",
      "12011                                        Unbiased  \n"
     ]
    }
   ],
   "source": [
    "def apply_tag(df):\n",
    "    \n",
    "    prompt: str = \"\"\"\n",
    "    You are an expert for linguistic media bias detection. You are asked to label the following text with one of the following labels:\n",
    "    Unbiased\n",
    "    Biased against Palestine\n",
    "    Biased against Israel\n",
    "    Biased against both Palestine and Israel\n",
    "    Biased against others\n",
    "    Unclear\n",
    "    Not Applicable.\n",
    "    There is not more context to include that what is given to you, so please make your best judgment based on the text alone. Just reply with the label. Here is the text:\n",
    "    \"\"\"\n",
    "    df['GPT proposal'] = df['English MT'].apply(lambda row: lm_completion([\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"system\", \"content\": row}]))\n",
    "    return df\n",
    "\n",
    "df_annotated = apply_tag(sample)\n",
    "print(df_annotated.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated.to_excel(\"annotated.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ID  Annotator ID_1  Annotator ID_2  Annotator ID_3  \\\n",
      "count     5.000000             5.0             5.0             5.0   \n",
      "mean   2085.400000             1.0             2.0             3.0   \n",
      "std    3926.991762             0.0             0.0             0.0   \n",
      "min      78.000000             1.0             2.0             3.0   \n",
      "25%      99.000000             1.0             2.0             3.0   \n",
      "50%     178.000000             1.0             2.0             3.0   \n",
      "75%     995.000000             1.0             2.0             3.0   \n",
      "max    9077.000000             1.0             2.0             3.0   \n",
      "\n",
      "       Annotator ID_4  N-way count bias  N-way count propaganda  \n",
      "count             5.0          5.000000                5.000000  \n",
      "mean              4.0          0.400000                0.400000  \n",
      "std               0.0          0.547723                0.547723  \n",
      "min               4.0          0.000000                0.000000  \n",
      "25%               4.0          0.000000                0.000000  \n",
      "50%               4.0          0.000000                0.000000  \n",
      "75%               4.0          1.000000                1.000000  \n",
      "max               4.0          1.000000                1.000000  \n"
     ]
    }
   ],
   "source": [
    "def tag_connotations(df):\n",
    "    prompt: str = \"\"\"\n",
    "    You are an expert for linguistic media bias detection. You are asked to label words in the following text with one of the following labels:\n",
    "    [negative]: meaning that the word has a negative connotation\n",
    "    [positive]: meaning that the word has a positive connotation\n",
    "    [factuality]: meaning that the word implies a doubt about the factuality of the statement\n",
    "    Focus on tagging verbs and adjectives and proper nouns. Do not tag named entities.\n",
    "    Directly apply the tag behind the word it applies to, for example:\n",
    "    This is an awful[negative] text.\n",
    "    Do not change anything else about the text, just add the tags, where applicable. Here is the text:\n",
    "    \"\"\"\n",
    "    df['GPT connotation'] = df['English MT'].apply(lambda row: lm_completion([\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"system\", \"content\": row}]))\n",
    "    return df\n",
    "\n",
    "df_annotated_connotations = tag_connotations(df.sample(5))\n",
    "print(df_annotated_connotations.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    }
   ],
   "source": [
    "df_annotated_connotations.to_excel(\"annotated_connotations.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Google Sheets with our Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_data(df_annotated_connotations[[\"GPT proposal\", \"GPT connotation\"]], worksheet, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
